# SimpleImageTo3DMeshConverter

For my B.Sc. thesis project, I created a small application for converting simple images - such as logos - into 3D models. The semi-autonomous program works by using an image as input, then outputs a 3D object file (.OBJ), which can then be used for 3D printing. 

The process consists of 5 main steps: 

1. Color Quantization: The number of unique pixel colors present in a typical logo image appears to be between 2 and 5 colors (a very small distinct number). However, the actual number of distinct colors present in the image is far greater. A standard logo image (with no apparent gradient) generally contains hundreds or even thousands of unique colors. This is due to the transitions between the colors located at the edges in the image, which allows the image to have the appearance of smooth edges, rather than sharp ones. Thus, the first step in the problem is to determine what are the dominant colors in the image, and reduce all of the colors in the image to those few that are visible. The resulting image will have sharp edges, which helps with the segmentation step. 

2. Image Segmentation: Digital images are represented as a grid (matrix) of numerical values, which does not help with determining any of the content within the image. Image segmentation is used to locate objects within an image. In this work, the Region Growing approach was used to decompose the image into regions, where each region consists of pixels of only a single color. 

3. Image Vectorization: Your typical image formats (.png, .jpg, .bmp, etc.) are all considered bitmap images, which means that they are represented as a fixed-sized matrix of color values. The problem with this format is that it cannot be scaled without losing quality. For example, if the image originally has a size of 100x100 pixels, and then is scaled 10 times the original size, the resulting image will have large jagged edges, and will be a blurry image overall. Vector images (or vector graphics) use a series of mathematical functions for lines and curves to represent the image, rather than a matrix of numbers. The vector format of the image is thus, scaleable, which is the reason that the vast majority of 3D modelling programs use vector graphics rather than bitmap. To simplify the vectorization process, the pixel edges around the exterior of each region boundary are traced with a series of lines (each line consists of two endpoints). However, in this case the quality of the vector image is no better than the bitmap, thus each line endpoint is smoothed in order to hide the pixel edges. 

4. Triangulation: Typical 3D mesh objects contain a series of planar faces made from points and edges. The standard number of edges per face is either 3 (for triangles) or 4, although the number of edges per face is not limited by any number (with the exception of a minimum of 3), and each face in the object may contain varying number of edges. To determine the faces for the top and bottom surfaces of the image, Delaunay triangulation was used on the 2D plane using the vectorized line endpoints as input. The resulting mesh was a 2D covering over the entire image, consisting of non-overlapping triangles. 

5. 3D Solid Generation: To generate the final 3D object, two instances of each triangular face was made with different heights: the first copy had a height of 0, representing the bottom surface of the model, and the second face had a height specified by the user, which is consistend within the color region (ie. all triangles within a given region from the segmented image are set to the same height). Finally, around the exterior edges of the region, rectangular faces were created between the top and bottom triangle faces, to form the outside walls of the model. The faces and vertices are then saved in the standard object format (.obj). 

